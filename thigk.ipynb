{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import librosa\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "\n",
    "# speech-silence and voice-unvoiced\n",
    "BASE_PATH = None\n",
    "\n",
    "\n",
    "def read_lab(lab_file_name: str):\n",
    "    \"\"\"Read lab file\n",
    "    lab_file_name: str, name of lab file\n",
    "    Return: list of lists [start_time, end_time, label]\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(lab_file_name) as f:\n",
    "        for line in f.readlines():\n",
    "            data.append(line.split())\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_closest(arr, values):\n",
    "    \"\"\"Get closest value in an sorted array\n",
    "    arr: np.ndarray\n",
    "    values: List of values to find\n",
    "    Return: List of closest values to input values\n",
    "    \"\"\"\n",
    "    arr = np.array(arr)\n",
    "    values = np.array(values, dtype=np.float64)\n",
    "    idx = np.searchsorted(arr, values)\n",
    "    idx = np.array(idx)\n",
    "    idx[arr[idx] - values > np.diff(arr).mean() * 0.5] -= 1\n",
    "    return arr[idx]\n",
    "\n",
    "\n",
    "def get_closest_idx(arr, values):\n",
    "    \"\"\"Get closest index in an sorted array\n",
    "    arr: np.ndarray\n",
    "    values: List of values to find\n",
    "    Return: List of closest index to input values\n",
    "    \"\"\"\n",
    "    arr = np.array(arr)\n",
    "    values = np.array(values, dtype=np.float64)\n",
    "    idx = np.searchsorted(arr, values, side='left')\n",
    "    idx = np.array(idx)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def array_norm(arr: np.ndarray):\n",
    "    min_arr=np.min(arr)\n",
    "    max_arr=np.max(arr)\n",
    "    return (arr-min_arr)/(max_arr-min_arr)\n",
    "\n",
    "def array_norm_by_threshold(arr: np.ndarray, threshold):\n",
    "    \"\"\"Normalize given function by threshold\n",
    "    arr: np.ndarray\n",
    "    T: threshold\n",
    "    \"\"\"\n",
    "    min_arr = min(arr)\n",
    "    max_arr = max(arr)\n",
    "    return np.where(arr >= threshold, (arr-threshold)/(max_arr-threshold), (arr-threshold)/(threshold-min_arr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(audio_name: str):\n",
    "    signal, sr = librosa.load(os.path.join(BASE_PATH, f'{audio_name}.wav'))\n",
    "    lab_data = read_lab(os.path.join(BASE_PATH, f'{audio_name}.lab'))\n",
    "    mean_std = lab_data[-2:]\n",
    "    timestamp_label = lab_data[:-2]\n",
    "    t_i = 0\n",
    "    t_f = signal.shape[0] / sr\n",
    "    t = np.linspace(t_i, t_f, num=signal.shape[0])\n",
    "    return signal, sr, t, timestamp_label\n",
    "\n",
    "\n",
    "def separate_frames(signal, sr, t, frame_length=0.02):\n",
    "    \"\"\"Separate signal into frames\n",
    "    signal: np.ndarray\n",
    "    sr: sampling rate\n",
    "    t: time array\n",
    "    frame_length: length of frame\n",
    "    Return: Array of frames\n",
    "    \"\"\"\n",
    "    frame_size = int(sr * frame_length)\n",
    "    frame_count = len(signal) // frame_size\n",
    "    signal_frames = []\n",
    "    for i in range(0, frame_count * frame_size, frame_size):\n",
    "        signal_frames.append(signal[i:i + frame_size])\n",
    "    return np.array(signal_frames), frame_size, frame_count\n",
    "\n",
    "def separate_sp_sl(STE, timestamp_label, t):\n",
    "    STE_sp = np.array([])\n",
    "    STE_sl = np.array([])\n",
    "    for line in timestamp_label:\n",
    "        if line[2] == 'sp':\n",
    "            try:\n",
    "                idx1 = int(get_closest_idx(t, line[0]))\n",
    "                idx2 = int(get_closest_idx(t, line[1]))\n",
    "                STE_sp = np.append(STE_sp, STE[idx1:idx2])\n",
    "            except:\n",
    "                print(line)\n",
    "        if line[2] == 'sl':\n",
    "            try:\n",
    "                idx1 = int(get_closest_idx(t, line[0]))\n",
    "                idx2 = int(get_closest_idx(t, line[1]))\n",
    "                STE_sl = np.append(STE_sl, STE[idx1:idx2])\n",
    "            except:\n",
    "                print(line)\n",
    "    return np.array(STE_sp), np.array(STE_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['studio_M2.wav', 'studio_F2.wav', 'phone_M2.wav', 'phone_M2.lab', 'phone_F2.lab', 'studio_M2.lab', 'studio_F2.lab', 'README', 'phone_F2.wav']\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['studio_M2', 'studio_F2', 'phone_M2', 'phone_F2']\n"
     ]
    }
   ],
   "source": [
    "global BASE_PATH\n",
    "BASE_PATH = 'TinHieuHuanLuyen'\n",
    "audio_name_list = list(filter(lambda x: x.endswith('.wav'), os.listdir(BASE_PATH)))\n",
    "audio_name_list = list(map(lambda x: x[:-4], audio_name_list))\n",
    "signal_list = [0]*len(audio_name_list)\n",
    "sr_list = [0]*len(audio_name_list)\n",
    "t_list = [0]*len(audio_name_list)\n",
    "timestamp_label_list = [0]*len(audio_name_list)\n",
    "signal_frames_list = [0]*len(audio_name_list)\n",
    "frame_size_list = [0]*len(audio_name_list)\n",
    "frames_count_list = [0]*len(audio_name_list)\n",
    "STE_list = [0]*len(audio_name_list)\n",
    "STE_speech_list = [0]*len(audio_name_list)\n",
    "STE_silence_list = [0]*len(audio_name_list)\n",
    "T_STE_list = [0]*len(audio_name_list)\n",
    "for audio in audio_name_list:\n",
    "    signal_list[i], sr_list[i], t_list[i], timestamp_label_list[i] = load_data(\n",
    "            audio_name_list[i])\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "signal_list[i], sr_list[i], t_list[i], timestamp_label_list[i] = load_data(\n",
    "            audio_name_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.28162307e-04,  2.69860262e-04,  6.54201722e-05, ...,\n",
       "        -3.36857338e-04, -9.89952678e-05,  1.19587174e-04], dtype=float32),\n",
       " 22050,\n",
       " array([0.00000000e+00, 4.53523374e-05, 9.07046749e-05, ...,\n",
       "        2.38176871e+00, 2.38181406e+00, 2.38185941e+00]),\n",
       " [['0.00', '0.45', 'sil'],\n",
       "  ['0.45', '0.48', 'uv'],\n",
       "  ['0.48', '0.77', 'v'],\n",
       "  ['0.77', '0.79', 'uv'],\n",
       "  ['0.79', '0.88', 'v'],\n",
       "  ['0.88', '0.92', 'uv'],\n",
       "  ['0.92', '1.32', 'v'],\n",
       "  ['1.32', '1.37', 'uv'],\n",
       "  ['1.37', '1.53', 'v'],\n",
       "  ['1.53', '1.59', 'uv'],\n",
       "  ['1.59', '1.93', 'v'],\n",
       "  ['1.93', '2.38', 'sil']])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_list[i], sr_list[i], t_list[i], timestamp_label_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16ccff9736ee8d8cf03c740ddb2b3365030232f12d1fada1b3e7c560bbc533bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
