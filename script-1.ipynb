{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# speech-silence and voice-unvoiced\n",
    "BASE_PATH = None\n",
    "\n",
    "\n",
    "def read_lab(lab_file_name: str):\n",
    "    \"\"\"Read lab file\n",
    "    lab_file_name: str, name of lab file\n",
    "    Return: list of lists [start_time, end_time, label]\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(lab_file_name) as f:\n",
    "        for line in f.readlines():\n",
    "            data.append(line.split())\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(audio_name: str):\n",
    "    \"\"\"\n",
    "    Load audio and lab file, create time vector with length equal to audio length\n",
    "    \"\"\"\n",
    "    signal, sr = librosa.load(os.path.join(BASE_PATH, f\"{audio_name}.wav\"))\n",
    "    lab_data = read_lab(os.path.join(BASE_PATH, f\"{audio_name}.lab\"))\n",
    "    timestamp_label = lab_data[:-2]\n",
    "    t_i = 0\n",
    "    t_f = signal.shape[0] / sr\n",
    "    t = np.linspace(t_i, t_f, num=signal.shape[0])\n",
    "    return signal, sr, t, timestamp_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cost(threshold):\n",
    "class SpeechSlienceDiscriminator:\n",
    "    \"\"\"\n",
    "    Class to predict speech-silence \n",
    "    \"\"\"\n",
    "    def __init__(self, audio_name, signal, sr, t, timestamp_label):\n",
    "        self.audio_name = audio_name\n",
    "        self.signal = signal\n",
    "        self.signal[self.signal == 0] = 1e-10\n",
    "        self.sr = sr\n",
    "        self.t = t\n",
    "        self.timestamp_label = timestamp_label\n",
    "        # calculate log_ste\n",
    "        self.calc_log_STE()\n",
    "        self.calc_silent_frame_idx()\n",
    "\n",
    "    def calc_log_STE(self, frame_length=0.02):\n",
    "        \"\"\"\n",
    "        Calculate log ste\n",
    "        \"\"\"\n",
    "        STE = []\n",
    "        frame_size = int(self.sr * frame_length)\n",
    "        frames_count = len(self.signal) // frame_size\n",
    "        frame_edges = []\n",
    "        for i in range(frames_count):\n",
    "            startIdx = i * frame_size\n",
    "            stop_Idx = startIdx + frame_size\n",
    "            window = np.zeros(self.signal.shape)\n",
    "            window[startIdx:stop_Idx] = 1\n",
    "            value = np.sum(np.square(self.signal) * window)\n",
    "            STE.append(value)\n",
    "            frame_edges.append(startIdx)\n",
    "        STE = np.array(STE)\n",
    "        STE = STE.reshape(-1)\n",
    "        frame_edges = np.array(frame_edges)\n",
    "        frame_edges = frame_edges.reshape(-1)\n",
    "        log_STE = np.log(STE)\n",
    "        self.log_STE = log_STE\n",
    "        self.frame_edges = frame_edges\n",
    "        return log_STE, frame_edges\n",
    "\n",
    "    def calc_silent_frame_idx(self):\n",
    "        \"\"\"\n",
    "        Create an array of 0 and 1, 1 if frame is in silence, 0 otherwise\n",
    "        \"\"\"\n",
    "        \n",
    "        silent_timestamps = list(filter(lambda x: x[2] == \"sil\", self.timestamp_label))\n",
    "        silent_timestamps = list(map(lambda x: x[:2], silent_timestamps))\n",
    "        silent_idx = []\n",
    "        for timestamp_pair in silent_timestamps:\n",
    "            start = float(timestamp_pair[0])\n",
    "            end = float(timestamp_pair[1])\n",
    "            start_idx = len(self.t[self.t < start])\n",
    "            end_idx = len(self.t[self.t < end])\n",
    "            silent_idx.append((start_idx, end_idx))\n",
    "        silent_frame_idx = []\n",
    "        for idx_pair in silent_idx:\n",
    "            frame_size = self.frame_edges[1] - self.frame_edges[0]\n",
    "            start_idx = int(idx_pair[0] / frame_size)\n",
    "            end_idx = int(idx_pair[1] / frame_size)\n",
    "            silent_frame_idx.append((start_idx, end_idx))\n",
    "        self.silent_frame_idx = silent_frame_idx\n",
    "        frame_in_silence = np.full(self.log_STE.shape, 0)\n",
    "        for idx_pair in self.silent_frame_idx:\n",
    "            frame_in_silence[idx_pair[0] : idx_pair[1] + 1] = 1\n",
    "        self.frame_in_silence = frame_in_silence\n",
    "\n",
    "    def plot_ste(self):\n",
    "        \"\"\"\n",
    "        Plot function, currently don't use\n",
    "        \"\"\"\n",
    "        plt.plot(self.log_STE, color=\"yellow\")\n",
    "        threshold = self.log_STE[self.silent_frame_idx[0][1]]\n",
    "        plt.axhline(y=threshold, color=\"red\")\n",
    "        for idx_pair in self.silent_frame_idx:\n",
    "            plt.axvline(x=idx_pair[0], color=\"red\")\n",
    "            plt.axvline(x=idx_pair[1], color=\"red\")\n",
    "        plt.show()\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def cross_entropy(self, y_hat):\n",
    "        y = self.frame_in_silence\n",
    "        y_hat[y_hat == 1] = 0.99999\n",
    "        loss = -(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "        return loss.sum() / len(self.log_STE)\n",
    "\n",
    "    def logistic_regression(self):\n",
    "        \"\"\"\n",
    "        Logistic regression with momentum\n",
    "        \"\"\"\n",
    "        epoch = 0\n",
    "        w = np.random.normal(size=(1,))\n",
    "        b = 0\n",
    "        z = w * self.log_STE + b\n",
    "        y_hat = self.sigmoid(z)\n",
    "        loss = self.cross_entropy(y_hat)\n",
    "        pv_w = [0]\n",
    "        pv_b = [0]\n",
    "        while (loss > 0.15) or epoch < 1000:\n",
    "            y = self.frame_in_silence\n",
    "            dLoss_dw = ((y_hat - y) * self.log_STE) / len(self.log_STE)\n",
    "            dLoss_db = (y_hat - y) / len(self.log_STE)\n",
    "            v_w = 0.9 * pv_w[-1] + 1 * dLoss_dw.sum()\n",
    "            v_b = 0.9 * pv_b[-1] + 1 * dLoss_db.sum()\n",
    "            w -= v_w\n",
    "            b -= v_b\n",
    "            z = w * self.log_STE + b\n",
    "            y_hat = self.sigmoid(z)\n",
    "            loss = self.cross_entropy(y_hat)\n",
    "            pv_w.append(v_w)\n",
    "            pv_b.append(v_b)\n",
    "            print(f\"{loss=}, {epoch=}\")\n",
    "            epoch += 1\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        return w, b\n",
    "\n",
    "    def predict(self):\n",
    "        print(self.frame_in_silence)\n",
    "        z = self.w * self.log_STE + self.b\n",
    "        y_hat = self.sigmoid(z)\n",
    "        y_hat[y_hat > 0.5] = 1\n",
    "        y_hat[y_hat <= 0.5] = 0\n",
    "        y_hat = y_hat.astype(int)\n",
    "        print(y_hat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"TinHieuHuanLuyen\"\n",
    "audio_name_train_list = list(\n",
    "    filter(lambda x: x.endswith(\".wav\"), os.listdir(BASE_PATH))\n",
    ")\n",
    "audio_name_train_list = list(map(lambda x: x[:-4], audio_name_train_list))\n",
    "signal_list = [0] * len(audio_name_train_list)\n",
    "sr_list = [0] * len(audio_name_train_list)\n",
    "t_list = [0] * len(audio_name_train_list)\n",
    "timestamp_label_list = [0] * len(audio_name_train_list)\n",
    "signal_frames_list = [0] * len(audio_name_train_list)\n",
    "frame_size_list = [0] * len(audio_name_train_list)\n",
    "frames_count_list = [0] * len(audio_name_train_list)\n",
    "i = 2\n",
    "signal_list[i], sr_list[i], t_list[i], timestamp_label_list[i] = load_data(\n",
    "    audio_name_train_list[i]\n",
    ")\n",
    "a = SpeechSlienceDiscriminator(\n",
    "    audio_name_train_list[i],\n",
    "    signal_list[i],\n",
    "    sr_list[i],\n",
    "    t_list[i],\n",
    "    timestamp_label_list[i],\n",
    ")\n",
    "a.logistic_regression()\n",
    "a.predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
